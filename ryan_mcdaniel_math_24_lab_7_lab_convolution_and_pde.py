# -*- coding: utf-8 -*-
"""Ryan McDaniel Math 24 Lab 7 Lab Convolution and PDE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HmxLlmVZuqSr4OhtlfQZkoP6da-2_EEt

Never Say Never - Documentary on Belousovâ€“Zhabotinsky Reaction BZ

https://www.youtube.com/watch?v=FvXwVZPOoBI


Image Kernels Explained Visually

https://setosa.io/ev/image-kernels/
"""

import numpy as np #libraries
from skimage import io as io
import matplotlib.pyplot as plt
from scipy import signal
import torch.nn.functional as F
from torch.nn.functional import *
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import time
from matplotlib import animation, rc
from IPython.display import HTML
rc('animation', html='html5')

def make_ani(A, colormap='gray'): #this function will run through a tensor to show an animated image

    fig, ax = plt.subplots()
    im = ax.imshow(A[0,:,:], cmap = colormap);
    ax.axis('off')
    fig.set_size_inches(12, 12) #these parameters define how we will use plt to show the images

    def animate(data, im): #set our first image
        im.set_data(data)

    def step(): #progress through the tensor updating the image for each frame
        for i in range(A.shape[0]):
            data = A[i,:,:]
            yield data

    return animation.FuncAnimation(fig, animate, step, interval=100, repeat=True, fargs=(im,)) #return the animation

def plot(x):
    fig, ax = plt.subplots()
    im = ax.imshow(x, cmap = 'gray')
    ax.axis('off')
    fig.set_size_inches(15, 15)
    plt.show() #define a universal plot function

image = io.imread("https://www.filfre.net/wp-content/uploads/2013/12/bbc4.png") #use imageio to read the url image

image.shape #the dimensions of our image

plot(image) #plot and show using our custom function

image.shape #get the shape again

plot(image[:,:,0]) #show just the red color channel (plot will default to black and white)

plot(image[:,:,1]) #now the green color channel

plot(image[:,:,2]) #this is the blue color channel

image.shape #our "image" is simply a tensor of data, which we can do mathematical operations on

image = np.mean(image, axis=2) #now we average out the color channels to get a black and white "image" (2d array of data)

plot(image) #this is the b and w data

image.shape #we have lost the third dimension by averaging it into one matrix

a = np.matrix([[1,2,1],[0,0,0],[-1,-2,-1]]) #now we create a feature, which we can use to do mathematical operations on the image 3x3x1 matrix

a

plot(a) #this is what our feature looks like

image.shape

y = signal.convolve2d(image, a, mode='same') #using the signal library we convolute our matrix with the image to create a featuremap

plot(y) #our feature map

a = np.transpose(a) #now we'll use the same feature but transpose it vertically and see what the convolution looks like

a

plot(a) #this is the feature

y = signal.convolve2d(image, a, mode='same') #convolute

plot(y) #now we get a feature map

b = np.random.random((25,25)) #now we'll make a random 25 x 25 value feature with values between zero and one

y = signal.convolve2d(image, b) #convolute them

plot(y) #and we have a randomly generated feature map

x = io.imread("https://ichef.bbci.co.uk/news/660/cpsprodpb/C342/production/_88068994_thinkstockphotos-493881770.jpg")
x = x[:,:,0] #lets get a new image and only take the red color channel from it

x = x.astype(float) #change the values between 0 and 255 to floats so we can divide them

x

x = x / 255.0 #change the values to be between zero and one so plt will understand them
plot(x) #there is the image

x #an "image" again is just numerical data

a #now we will use our earlier feature

a[1,1] #what is the central value of our feature?

def conv2(x,f): #make a convolution function of our own rather than using the one out of the library
    x2 = np.zeros(x.shape) #make a new array with the same size as our input array
    for i in range(1,x.shape[0]-1): #if we multiply across the whole image we will have some undefined values so we shrink our zone of attack by the size of the feature
        for j in range(1,x.shape[1]-1):

            x2[i,j] = f[0,0] * x[i-1,j-1]  \ #we will set each data point in our new array to be the sum of all the necessary multiplications in our feature
            +         f[0,1] * x[i-1,j]    \
            +         f[0,2] * x[i-1,j+1]  \
            +         f[1,0] * x[i,j-1]    \
            +         f[1,1] * x[i,j]      \
            +         f[1,2] * x[i,j+1]    \
            +         f[2,0] * x[i+1,j-1]  \
            +         f[2,1] * x[i+1,j]    \
            +         f[2,2] * x[i+1,j+1]

    return x2 #return our new image

a = np.matrix([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]]) #this is a common outline feature
# a = np.matrix([[1,2,1],[0,0,0],[-1,-2,-1]])
# a = np.matrix([[1,1,1],[1,1,1],[1,1,1]])
# a = 5*np.random.random((3,3))-5*np.random.random((3,3))

a

z = conv2(x,a) #lets use our convolution function to see our array through the outline feature feature map

plot(z)

for i in range(10): #now we'll generate 10 random features and see what our image looks like with each of them
    a = 2*np.random.random((3,3))-1
    print(a)
    z=conv2(x,a)
    plot(z)



#Homemade Conv Loop Timing
a = 2*np.random.random((9,3,3))-1 #now we will test how long it takes our convolution to do its work
start_time = time.time()
for i in range(9):

    z=conv2(x,a[i,:,:])

print("Seconds:", (time.time() - start_time)) #far too long

#Optimized Code Timing
a = 2*np.random.random((9,3,3))-1 #using the library optimized code takes much less time
start_time = time.time()
for i in range(9):

    z = signal.convolve2d(x,a[i,:,:])

print("--- %s seconds ---" % (time.time() - start_time)) #about 1/100th of the time, this is because it uses the GPU not the CPU

#GPU Processing Timing, No Loop, 96 filters!!
a2 = 2*np.random.random((96,1,3,3))-1
x2 = torch.tensor(x).cuda()
a2 = torch.tensor(a2).cuda()
x2 = x2[None,None,:,:]

start_time = time.time()
z = conv2d(x2,a2)
print("--- %s seconds ---" % (time.time() - start_time)) #we can do 96 random features in around half a second just by using the gpu, which is better at small simple calculations than a cpu

z.shape #now we have a tensor with only one color channel but 96 different featuremaps of the same array



image = io.imread("https://img.jagranjosh.com/imported/images/E/Articles/Fastest-Fish-img.jpg").astype(float)/255.0 #lets get an image, change it to decimal color
plot(image) #plot it

image.shape #this image is bigger and still has three color channels

plot(np.random.random((11,11,3))) #now we can make a feature that also has three color channels rather than having to do it to a 2d array we can do it with a 3d tensor

image = np.transpose(image, (2, 0, 1)) #we transpose the image so the color channel is first then the horizontal then vertical stacks

image.shape #we see that the dimensions have changed position

f = np.random.random((1,3,11,11)) #we will make another random feature 4 dimensional (the first dimension represents frames)

image.shape

image = image[None,:,:,:] #change our image to be the first frame in a tensor

image.shape,f.shape #now we see that the first two dimensions of our image and feature match up

f =  torch.tensor(f) #change them to pytorch tensors so we can use the common pytorch Object variables
image =  torch.tensor(image)

image2 = F.conv2d(image,f) #we will 2d convolute using our feature and our data (this is why we had to change the dimensions so it would be set up for pytorch)

image2 = image2.numpy() #change it back to a numpy array

image2.shape #now we see our new featuremap has the same dimensions as our first image

image2[0,0,:,:].shape #whats the shape of the red channel of our first frame

plot(image2[0,0,:,:]) #what does it look like?



image = io.imread("http://ian-albert.com/games/super_mario_bros_maps/mario-2-2.gif") #now we'll do an image search using a feature
image = image[:,0:700,:] #we'll change the dimensions to be this small part of the image
plot(image) #show it

coin = image[185:200,224:239,:] #now instead of manually making our feature we'll take it out of our image

plot(coin) #this is what the feature looks like

image = image[60:,0:700,:] #shrink even more
plot(image) #show it

def scale1(x): #find our max and min values of x so we can define what 100% and 0% are for an array of differing size
    return (x-np.min(x))/(np.max(x)-np.min(x))

image = np.mean(image,axis=2) #we take the mean of the array and the feature and use the scale function to make all values between 0 and 1
coin = np.mean(coin,axis=2)

image = scale1(image)
coin = scale1(coin)

plot(image) #show our image and feature
plot(coin)

coin.shape #our feature is 15x15

image = image - np.mean(image) #subtract the mean of the image from itself to normalize it
coin = coin - np.mean(coin) #same with feature

image.shape,coin.shape

coin = np.rot90(coin, 2) #rotate 90 degrees, twice

plot(coin)

z = signal.convolve2d(image,coin) #now we convolute the feature and array to find where they match up exactly (where the value is one)

# z = conv2(image,coin)

plot(z) #we find that they match exactly where the coins are in the original image and we get a little white dot where they match

z == np.max(z)

plot(z==np.max(z)) #now we only show where the feature map matches exactly

np.where(z == np.amax(z)) #we find the coordinates of those spots

[y,x] = np.where(z == np.amax(z))

plt.plot(x,-y,'.') #now we can plot those coordinates

fig, ax = plt.subplots() #if we plot them over each other we can see where the coins are
im = ax.imshow(image, cmap = 'gray')
ax.axis('off')
ax.scatter(x-6, y-6, c='red', s=40)
fig.set_size_inches(18, 10)







def conv2(w,f): #GPU conv with padding #now lets make our own convolution using torch

    n = conv2d(w.type(torch.int),f.type(torch.int))
    n = pad(n, (1, 1, 1, 1)) #add ones to the sides of the matrix

    return n

#Game of Life

w = (np.random.random((100,100)) > 0.5) #game of life world grid w
f = np.matrix([[1,1,1],[1,0,1],[1,1,1]]) #this is our feature

f

plot(w) #what our game of life grid looks like

steps = 1000 #we change it to 1000 frames
A = torch.zeros((steps,100,100)) # storage for frames for animation
w = torch.tensor(w.astype(int))[None,None,:,:]
f = torch.tensor(f.astype(int))[None,None,:,:]

# %%timeit
n = conv2(w,f) #see how long it takes

# (n==2)[0,0,:,:].shape

plot((n==2)[0,0,:,:]) #plot the new grid

for i in range(steps): #we will convolute our animation then use our earlier function to display it

    n = conv2(w,f)

    w = (w * (n==2)) + (n==3)

    A[i] = w

make_ani(A) #the tensor animated







#Surface Tension Model

w = (np.random.random((100,100)) > 0.5).astype(int)
f = np.matrix([[1,1,1],[1,1,1],[1,1,1]])

steps = 200
A = torch.zeros((steps,100,100)) # storage for frames for animation
w = torch.tensor(w)[None,None,:,:]
f = torch.tensor(f)[None,None,:,:]

for i in range(steps):

    n = conv2(w,f)

    w = ~((n<4) + (n==5))

    A[i] = w

make_ani(A)



#Forest Fire Model

# veg = {empty=0 burning=1 green=2}

Plightning = 0.00005
Pgrowth = 0.01

w = (np.random.random((100,100)) > 0.5).astype(int)
f = np.matrix([[1,1,1],[1,0,1],[1,1,1]])

steps = 1000
A = torch.zeros((steps,100,100)) # storage for frames for animation
w = torch.tensor(w)[None,None,:,:]
f = torch.tensor(f)[None,None,:,:]

for i in range(steps):

    n = w == 1

    n = conv2(n,f)

    w =  2*((w == 2)).type(torch.int)                                                \
    -    1*((w == 2) * ( n > 0 ) ).type(torch.int)                                   \
    -    1*((w == 2) * ( np.random.random((100,100)) < Plightning)).type(torch.int)  \
    +    2*((w == 0) * ( np.random.random((100,100)) < Pgrowth)).type(torch.int)

    A[i] = w

make_ani(A, colormap='magma')





#Nonlinear Waves

w = np.random.random((100,100)) < 0.1
f = np.matrix([[1,1,1],[1,0,1],[1,1,1]])

t  = 6  #center value=6; 7 makes fast pattern; 5 analiating waves
t1 = 3  #center value=3

steps = 1000
A = torch.zeros((steps,100,100)) # storage for frames for animation
w = torch.from_numpy(w)[None,None,:,:]
f = torch.from_numpy(f)[None,None,:,:]

for i in range(1000):

    n = (w>0)&(w<t)

    n = conv2(n,f)

    w = ((w==0) & (n>=t1)) \
    +  2*(w==1)            \
    +  3*(w==2)            \
    +  4*(w==3)            \
    +  5*(w==4)            \
    +  6*(w==5)            \
    +  7*(w==6)            \
    +  8*(w==7)            \
    +  9*(w==8)            \
    +  0*(w==9)            \

    A[i] = w

make_ani(A)





#Wireword Wire
#{empty=0 electron_head=1 electron_tail=2, wire=3}

w = np.zeros((100,100))
w[50,:] = 3
w[50,5] = 2
w[50,6] = 1

f = np.matrix([[1,1,1],[1,0,1],[1,1,1]])

steps = 1000
A = torch.zeros((steps,100,100)) # storage for frames for animation
w = torch.from_numpy(w)[None,None,:,:]
f = torch.from_numpy(f)[None,None,:,:]

for i in range(100):

    n=w==1

    n = conv2(n,f)

    w = 1*((w==3)& ((n==1) | (n==2)))                 \
    +   3*((w==3)& ((n!=1) & (n!=2)))                 \
    +   0*(w==0)                    \
    +   2*(w==1)                    \
    +   3*(w==2)                    \

    A[i] = w

make_ani(A, colormap='magma')



#Wireworld Oscillator

w = np.zeros((100,100))
w[50,15:-1] = 3
w[48,5:15] = 3
w[52,5:15] = 3
w[49:52,4] = 3
w[49:52,15] = 3
w[52,14] = 1
w[52,13] = 2

f = np.matrix([[1,1,1],[1,0,1],[1,1,1]])

steps = 1000
A = torch.zeros((steps,100,100)) # storage for frames for animation
w = torch.from_numpy(w)[None,None,:,:]
f = torch.from_numpy(f)[None,None,:,:]

for i in range(steps):

    n = w == 1

    n = conv2(n,f)

    w = 0*((w==0))                                    \
    +   2*((w==1))                                    \
    +   3*((w==2))                                    \
    +   3*((w==3)& ((n!=1) & (n!=2)))                 \
    +   1*((w==3)& ((n==1) | (n==2)))                 \

    A[i] = w

make_ani(A, colormap='magma')





#FitzHugh-Nagumo Reaction Diffusion

def laplacian(U):
    n = conv2d(U,laplace)
    n = pad(n, (1, 1, 1, 1),'circular')
    return n

laplace = 0.5*np.array([[0.5, 1.0, 0.5],
                        [1.0, -6., 1.0],
                        [0.5, 1.0, 0.5]])

N = 256
h = 0.05

A = np.zeros([N, N], dtype=np.float32)

A = A + -0.7

noise_shape = A[:,120:130].shape

A[:,120:130] = (np.random.normal(0.9,0.05,size=noise_shape))

B = np.zeros([N, N], dtype=np.float32)

B = B + -0.3

w1 = plot(A)

a0 = -0.1
a1 = 2
epsilon = 0.05
delta = 4
k1 = 1
k2 = 0
k3 = 1

A = torch.from_numpy(A)[None,None,:,:].cuda()
B = torch.from_numpy(B)[None,None,:,:].cuda()
laplace = torch.from_numpy(laplace)[None,None,:,:].type(torch.float).cuda()

steps = 100
P = torch.zeros((steps,N,N)) # storage for frames for animation

j = 0
for i in range(steps*1000):

    A += h*( k1*A - k2*A**2 - A**3 - B + laplacian(A))
    B += h*( epsilon*(k3*A - a1*B -a0) + delta*laplacian(B) )

    if i % 1000 == 0:
        P[j] = A
        j += 1

make_ani(P)



#Gray Scott Reaction Diffusion

laplace = 0.5*np.array([[0.5, 1.0, 0.5],
                        [1.0, -6., 1.0],
                        [0.5, 1.0, 0.5]])

laplace = torch.from_numpy(laplace)[None,None,:,:].type(torch.float).cuda()

def laplacian(U):
    n = conv2d(U,laplace)
    n = pad(n, (1,1,1,1))
    n = pad(n, (0,0,0,0))
    return n

(Du, Dv, F, k) = ((0.16, 0.08, 0.035, 0.065)) # Bacteria 1
# (Du, Dv, F, k) = ((0.14, 0.06, 0.035, 0.065)) # Bacteria 2
# (Du, Dv, F, k) = ((0.16, 0.08, 0.060, 0.062)) # Coral
# (Du, Dv, F, k) = ((0.19, 0.05, 0.060, 0.062)) # Fingerprint
# (Du, Dv, F, k) = ((0.10, 0.10, 0.018, 0.050)) # Spirals
# (Du, Dv, F, k) = ((0.12, 0.08, 0.020, 0.050)) # Spirals Dense
# (Du, Dv, F, k) = ((0.10, 0.16, 0.020, 0.050)) # Spirals Fast
# (Du, Dv, F, k) = ((0.16, 0.08, 0.020, 0.055)) # Unstable
# (Du, Dv, F, k) = ((0.16, 0.08, 0.050, 0.065)) # Worms 1
# (Du, Dv, F, k) = ((0.16, 0.08, 0.054, 0.063)) # Worms 2
# (Du, Dv, F, k) = ((0.16, 0.08, 0.035, 0.060)) # Zebrafish

N = 256

U = np.zeros((N,N)) # Clear Chemicals
V = np.zeros((N,N))

U = U + 1.0
r = 5
U[N//2-r:N//2+r,N//2-r:N//2+r] = 0.50 # Add Disturbance in Center Square Radius r
V[N//2-r:N//2+r,N//2-r:N//2+r] = 0.25

U += 0.05*np.random.random((N,N)) # Add Noise to Chemicals
V += 0.05*np.random.random((N,N))

U = torch.from_numpy(U)[None,None,:,:].type(torch.float).cuda()
V = torch.from_numpy(V)[None,None,:,:].type(torch.float).cuda()

steps = 2000
skip = 100
P = torch.zeros((steps,N,N)) # storage for frames for animation

j = 0
for i in range(steps*skip):

    U += ( Du*laplacian(U) - U*V**2 +  F   *(1-U) )
    V += ( Dv*laplacian(V) + U*V**2 - (F+k)*V     )

    if i % skip == 0:
        P[j] = U
        j += 1

make_ani(P)











# (Du, Dv, F, k) = ((0.16, 0.08, 0.035, 0.065)) # Bacteria 1
# (Du, Dv, F, k) = ((0.14, 0.06, 0.035, 0.065)) # Bacteria 2
# (Du, Dv, F, k) = ((0.16, 0.08, 0.060, 0.062)) # Coral
# (Du, Dv, F, k) = ((0.19, 0.05, 0.060, 0.062)) # Fingerprint
# (Du, Dv, F, k) = ((0.10, 0.10, 0.018, 0.050)) # Spirals
# (Du, Dv, F, k) = ((0.12, 0.08, 0.020, 0.050)) # Spirals Dense
# (Du, Dv, F, k) = ((0.10, 0.16, 0.020, 0.050)) # Spirals Fast
# (Du, Dv, F, k) = ((0.16, 0.08, 0.020, 0.055)) # Unstable
# (Du, Dv, F, k) = ((0.16, 0.08, 0.050, 0.065)) # Worms 1
# (Du, Dv, F, k) = ((0.16, 0.08, 0.054, 0.063)) # Worms 2
(Du, Dv, F, k) = ((0.16, 0.08, 0.035, 0.060)) # Zebrafish

N = 256

U = np.zeros((N,N)) # Clear Chemicals
V = np.zeros((N,N))

U = U + 1.0
r = 5
U[N//2-r:N//2+r,N//2-r:N//2+r] = 0.50 # Add Disturbance in Center Square Radius r
V[N//2-r:N//2+r,N//2-r:N//2+r] = 0.25

U += 0.05*np.random.random((N,N)) # Add Noise to Chemicals
V += 0.05*np.random.random((N,N))

U = torch.from_numpy(U)[None,None,:,:].type(torch.float).cuda()
V = torch.from_numpy(V)[None,None,:,:].type(torch.float).cuda()

steps = 2000
skip = 100
P = torch.zeros((steps,N,N)) # storage for frames for animation

j = 0
for i in range(steps*skip):

    U += ( Du*laplacian(U) - U*V**2 +  F   *(1-U) )
    V += ( Dv*laplacian(V) + U*V**2 - (F+k)*V     )

    if i % skip == 0:
        P[j] = U
        j += 1

make_ani(P)









# (Du, Dv, F, k) = ((0.16, 0.08, 0.035, 0.065)) # Bacteria 1
# (Du, Dv, F, k) = ((0.14, 0.06, 0.035, 0.065)) # Bacteria 2
(Du, Dv, F, k) = ((0.16, 0.08, 0.060, 0.062)) # Coral
# (Du, Dv, F, k) = ((0.19, 0.05, 0.060, 0.062)) # Fingerprint
# (Du, Dv, F, k) = ((0.10, 0.10, 0.018, 0.050)) # Spirals
# (Du, Dv, F, k) = ((0.12, 0.08, 0.020, 0.050)) # Spirals Dense
# (Du, Dv, F, k) = ((0.10, 0.16, 0.020, 0.050)) # Spirals Fast
# (Du, Dv, F, k) = ((0.16, 0.08, 0.020, 0.055)) # Unstable
# (Du, Dv, F, k) = ((0.16, 0.08, 0.050, 0.065)) # Worms 1
# (Du, Dv, F, k) = ((0.16, 0.08, 0.054, 0.063)) # Worms 2
# (Du, Dv, F, k) = ((0.16, 0.08, 0.035, 0.060)) # Zebrafish

N = 256

U = np.zeros((N,N)) # Clear Chemicals
V = np.zeros((N,N))

U = U + 1.0
r = 5
U[N//2-r:N//2+r,N//2-r:N//2+r] = 0.50 # Add Disturbance in Center Square Radius r
V[N//2-r:N//2+r,N//2-r:N//2+r] = 0.25

U += 0.05*np.random.random((N,N)) # Add Noise to Chemicals
V += 0.05*np.random.random((N,N))

U = torch.from_numpy(U)[None,None,:,:].type(torch.float).cuda()
V = torch.from_numpy(V)[None,None,:,:].type(torch.float).cuda()

steps = 8000
skip = 100
P = torch.zeros((steps,N,N)) # storage for frames for animation

j = 0
for i in range(steps*skip):

    U += ( Du*laplacian(U) - U*V**2 +  F   *(1-U) )
    V += ( Dv*laplacian(V) + U*V**2 - (F+k)*V     )

    if i % skip == 0:
        P[j] = U
        j += 1

make_ani(P)

