# -*- coding: utf-8 -*-
"""Ryan McDaniel Math 24 Lab 9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n3G8vnkrSduxlsO6eOzJl2vHxiZhKUnI

## Setup

### Imports
"""

import numpy as np #libraries
import matplotlib.pyplot as plt
import urllib.request
from PIL import Image
from imageio import *
import torch
from skimage.transform import resize
from mpl_toolkits.axes_grid1.axes_rgb import make_rgb_axes, RGBAxes
from torchvision.models import *
from torchvision.datasets import MNIST,KMNIST,FashionMNIST
from skimage.util import montage

!pip install wandb #install weights and biases
import wandb as wb

def plot(x): #this plot function will allow us to plot both numpy arrays and torch tensors
    if type(x) == torch.Tensor : #if we have a torch tensor we change it to a numpy array
        x = x.cpu().detach().numpy()

    fig, ax = plt.subplots() #and we set the defaults for matplotlib
    im = ax.imshow(x, cmap = 'gray') #gray colormap
    ax.axis('off') #axis off
    fig.set_size_inches(5, 5) #size
    plt.show() #show the plot

def montage_plot(x): #this function pads the second and third dimensions of our an array with constant values
    x = np.pad(x, pad_width=((0, 0), (1, 1), (1, 1)), mode='constant', constant_values=0)
    plot(montage(x))

b = 1000 #we set a univeral b for our batch size

def get_batch(mode): #let's make a function to train on data or guess unknown data
    if mode == "train": #training mode
        r = np.random.randint(X.shape[0]-b)
        x = X[r:r+b,:]
        y = Y[r:r+b]
    elif mode == "test": #guess mode
        r = np.random.randint(X_test.shape[0]-b)
        x = X_test[r:r+b,:]
        y = Y_test[r:r+b]
    return x,y #return our guesses

"""## MNIST

### Load Data
"""

# #MNIST
train_set = MNIST('./data', train=True, download=True)
test_set  = MNIST('./data', train=False, download=True)

#KMNIST
# train_set = KMNIST('./data', train=True, download=True)
# test_set =  KMNIST('./data', train=False, download=True)

# Fashion MNIST
# train_set = FashionMNIST('./data', train=True, download=True)
# test_set =  FashionMNIST('./data', train=False, download=True)

X = train_set.data.numpy() #we will change our MNIST objects to numpy arrays
X_test = test_set.data.numpy()
Y = train_set.targets.numpy()
Y_test = test_set.targets.numpy()

X = X[:,None,:,:]/255 #we'll divide them by 255 to get decimal form for matplotlib plotting
X_test = X_test[:,None,:,:]/255

X.shape #size of X

Y[50000] #in our set of answers, we see that the 50,000th index of X should be a three

plot(X[50000,0,:,:]) #we can plot x to see what it looks like, and it is a three

Y[100] #the 100th image should be a 5

X.shape #again we look at our indeces for X

X[0:25,0,:,:].shape #we see that we have 25 28x28 images in the first 25 indeces of X

montage_plot(X[125:150,0,:,:]) #we plot them all together using our montage plot function from earlier

X.shape[0] #there are 60000 pictures in our X

X_test.shape #we only use the first 10,000 for our test

X.shape[0]

X_test.shape[0]

def GPU(data): #these functions will change our numpy arrays to torch tensor objects, one for gradient data and one for non-gradient
    return torch.tensor(data, requires_grad=True, dtype=torch.float, device=torch.device('cuda'))

def GPU_data(data):
    return torch.tensor(data, requires_grad=False, dtype=torch.float, device=torch.device('cuda'))

X = GPU_data(X) #let's convert our numpy arrays to tensor objects using the functions we defined
Y = GPU_data(Y)
X_test = GPU_data(X_test)
Y_test = GPU_data(Y_test)

X = X.reshape(X.shape[0],784)  #we flatten them both into vectors
X_test = X_test.reshape(X_test.shape[0],784)

X.shape #this will allow us to use the classifier

"""
### Classifier
"""

x,y = get_batch('train') #we'll get another batch using the function we defined earlier, and it will have our specified batch size

x.shape #the size of our batch

plot(x[0].reshape(28,28)) #we will unflatten and plot the first image

plot(x[1].reshape(28,28)) #second image

plot(x[2].reshape(28,28)) #third image

y[:10] #now we see what the first 10 guesses of our y

W = GPU(np.random.randn(784,10)) #we'll make 10 normally distributed random matrixes and convert them to torch tensors



x.shape, W.shape #because the second and first dimensions match, we can do matrix multiplication on them

torch.matmul(x,W).shape #what is the size if we multiply the matrices?

(x@W).shape #@ is shortcut for matrix multiplication

# Commented out IPython magic to ensure Python compatibility.
# %%timeit
# x@W #we see how quickly the gpu can perform even this massive matrix multiplication

x@W #now we look at the resulting matrix

y2 = x@W #lets save it to a variable

plot(y2[:50]) #plotting the first 50 rows in our results matrix we see that its a set of random values

y #our answer key

y.shape #we see that the size of the key for the batch is 1000

def one_hot(y): #we'll make a function to store our guesses in a "one-hot vector" a vector which stores the values in a binary fashion
    y2 = GPU_data(torch.zeros((y.shape[0],10)))
    for i in range(y.shape[0]):
        y2[i,int(y[i])] = 1 #this line sets each value in our vector to a binary representation of the answer key for our batch (0-10)
    return y2 #y2 ends up being a matrix which is 10 (number of possibilities) by 1000 (batch size) answer key

one_hot(y) #now instead of having the values represented in our key we have the positional representation of what each image represents numerically

torch.argmax(y2,1) #this will return the highest value correlation in our matrix multiplication result

torch.sum(y == torch.argmax(y2,1))/b #we calculate our accuracy by seeing how close our y2 value is to the sum of our key divided by batch size
#we see the accuracy is near 10% as we're just randomly guessing

X.shape #this is the full dataset

X@W

torch.argmax(X@W,1) #now we can multiply our entire dataset by our randomly generated weights

Y

torch.sum(torch.argmax(X@W,1) == Y)/60000 #the accuracy of doing the whole matrix is also near 10%, since the guesses are completely random

X@W

W.shape #our weights need to be changed to get a more accurate result

W[:,0].shape #each weight index has a size of 784, which is 28x28

plot(W[:,0].reshape(28,28)) #as we can see, this is currently what we are guessing that a zero looks like

plot(W[:,2].reshape(28,28)) #and this is what we think a two looks like

W.shape

(W.T).shape

montage_plot((W.T).reshape(10,28,28).cpu().detach().numpy()) #these are our features for how each number looks in theory, as you can see not very accurate

def softmax(x): #lets make a new softmax function so we can calculate our loss
    s1 = torch.exp(x - torch.max(x,1)[0][:,None])
    s = s1 / s1.sum(1)[:,None]
    return s

def cross_entropy(outputs, labels): #defining our entropy helps us calculate our error
    return -torch.sum(softmax(outputs).log()[range(outputs.size()[0]), labels.long()])/outputs.size()[0]

def acc(out,y): #this function shows us what our accuracy is
    return (torch.sum(torch.max(out,1)[1] == y).item())/y.shape[0]

def get_batch(mode): #the only difference between this function and the earlier batching function is we have a dynamic batch sizing
    b = c.b
    if mode == "train":
        r = np.random.randint(X.shape[0]-b)
        x = X[r:r+b,:]
        y = Y[r:r+b]
    elif mode == "test":
        r = np.random.randint(X_test.shape[0]-b)
        x = X_test[r:r+b,:]
        y = Y_test[r:r+b]
    return x,y

def model(x,w): #we can view our model of any given number by returning the first index of our matrix multiplication

    return x@w[0]

def gradient_step(w): #gradient step will slowly correct our modelling based off of our error

    w[0].data = w[0].data - c.L*w[0].grad.data

    w[0].grad.data.zero_()

def make_plots(): #using weights and biases we will train our network

    acc_train = acc(model(x,w),y)

    xt,yt = get_batch('test')

    acc_test = acc(model(xt,w),yt)

    wb.log({"acc_train": acc_train, "acc_test": acc_test})

def Truncated_Normal(size): #same truncated normally generated randomizer as the last lab

    u1 = torch.rand(size)*(1-np.exp(-2)) + np.exp(-2)
    u2 = torch.rand(size)
    z  = torch.sqrt(-2*torch.log(u1)) * torch.cos(2*np.pi*u2)

    return z

for run in range(3): #lets run our data 3 times and see how much the modelling improves

    wb.init(project="Simple_Linear_SGD_123");
    c = wb.config

    c.L = 0.1
    c.b = 1024
    c.epochs = 10000

    w = [GPU(Truncated_Normal((784,10)))]

    for i in range(c.epochs):

        x,y = get_batch('train')

        out = model(x,w)

        loss = cross_entropy(softmax(out),y)

        loss.backward()

        gradient_step(w)

        make_plots()

        if (i+1) % 10000 == 0: montage_plot((w[0].T).reshape(10,28,28).cpu().detach().numpy())

for run in range(100): #doesn't get much better with only three runs, but will 100 improve it more?

    wb.init(project="Simple_Linear_Adam_2");
    c = wb.config

    c.L = 0.01
    c.b = 1024
    c.epochs = 100000

    w = [GPU(Truncated_Normal((784,10)))]

    optimizer = torch.optim.Adam(w, lr=c.L)

    for i in range(c.epochs):

        x,y = get_batch('train')

        loss = cross_entropy(softmax(model(x,w)),y)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        wb.log({"loss": loss})

        make_plots()

        if i % 10000 == 0 : montage_plot((w[0].T).reshape(10,28,28).cpu().detach().numpy())

"""
### Autoencoder
"""

def get_batch(mode): #we'll set our batch size to the very common 1024
    b = 1024
    if mode == "train":
        r = np.random.randint(X.shape[0]-b)
        x = X[r:r+b,:]
        y = Y[r:r+b]
    elif mode == "test":
        r = np.random.randint(X_test.shape[0]-b)
        x = X_test[r:r+b,:]
        y = Y_test[r:r+b]
    return x,y

X = X.reshape(X.shape[0],1,28,28)
X_test = X_test.reshape(X_test.shape[0],1,28,28)

import torchvision #torch vision helps us visualize our data
from torch.nn.functional import *

X = torchvision.transforms.functional.normalize(X,0.5,0.5) #let's normalize the data so its easier to compare
X_test = torchvision.transforms.functional.normalize(X_test,0.5,0.5)

def Encoder(x,w): #the encoder will matmul the feature across each image 2 pixels at a time
    x = relu(conv2d(x,w[0], stride=(2, 2), padding=(1, 1))) #horizontally
    x = relu(conv2d(x,w[1], stride=(2, 2), padding=(1, 1))) #vertically
    x = x.view(x.size(0), 6272)
    x = linear(x,w[2])
    return x #we return the featuremap, which will eventually become a vector

def Decoder(x,w): #decoder takes our vectors and turns them back into tensor images
    x = linear(x,w[3])
    x = x.view(x.size(0), 128, 7, 7)
    x = relu(conv_transpose2d(x,w[4], stride=(2, 2), padding=(1, 1)))
    x = torch.tanh(conv_transpose2d(x,w[5], stride=(2, 2), padding=(1, 1))) #we essentially do the exact inverse of our encoder function
    return x #return the tensor

def Autoencoder(x,w): #we'll see that we lose some data doing this, but it will give us a better feature to use over time
    return Decoder(Encoder(x,w),w)

num_steps = 1000 #lets define how many steps we'll take in our training, batch size, and learning rate, which determines how far the line of best fit moves from its previous position with each new step
batch_size = 512
learning_rate = 1e-3

from scipy import stats #more libraries
import numpy as np
import matplotlib.pyplot as plt
import urllib.request
from PIL import Image
from imageio import *
import torch
from skimage.transform import resize
from mpl_toolkits.axes_grid1.axes_rgb import make_rgb_axes, RGBAxes
from torchvision.models import *
from torchvision.datasets import MNIST,KMNIST,FashionMNIST
from skimage.util import montage

def randn_trunc(s): #Truncated Normal Random Numbers
    mu = 0
    sigma = 0.1
    R = stats.truncnorm((-2*sigma - mu) / sigma, (2*sigma - mu) / sigma, loc=mu, scale=sigma)
    return R.rvs(s)

#Encode
w0 = GPU(randn_trunc((64,1,4,4)))
w1 = GPU(randn_trunc((128,64,4,4)))
w2 = GPU(randn_trunc((10,6272)))
#Decode
w3 = GPU(randn_trunc((6272,10)))
w4 = GPU(randn_trunc((128,64,4,4)))
w5 = GPU(randn_trunc((64,1,4,4)))

w = [w0,w1,w2,w3,w4,w5] #we'll get our random weights matrices into one big tensor

optimizer = torch.optim.Adam(params=w, lr=learning_rate) #we'll use the built in optimizer with our set learning rate and weights

for i in range(num_steps): #now lets train our network, and use the autoencoder to see our generated images

    x_real,y = get_batch('train')

    x_fake = Autoencoder(x_real,w)

    loss = torch.mean((x_fake - x_real)**2) #now the difference between our fake and real squared gives us the loss function

    optimizer.zero_grad() #turn off gradient
    loss.backward() #now we back propogate the loss (this updates our weights)
    optimizer.step() #and we move forward in the steps

    if i % 100 == 0: print(loss.item()) #every 100 steps we print our loss

image_batch,y = get_batch('test') #we see the loss is lower as time progresses

image_batch_recon = Autoencoder(image_batch,w) #we'll get a new batch and using our updated weights after the training, we'll autoencode the batch (with unknown results)

torch.mean((image_batch_recon - image_batch)**2) #our loss is around 7%

montage_plot(image_batch[0:25,0,:,:].cpu().detach().numpy()) #now we plot the real batch

montage_plot(image_batch_recon[0:25,0,:,:].cpu().detach().numpy()) #and we see the batch our network generates with the autoencoder is similar to the original

"""
### Generator

"""



latent_size = 64
hidden_size = 256 #set some default values
image_size = 784
b = 1024

#MNIST
# train_set = MNIST('./data', train=True, download=True)
# test_set = MNIST('./data', train=False, download=True)

#KMNIST
#train_set = KMNIST('./data', train=True, download=True)
#test_set = KMNIST('./data', train=False, download=True)

#Fashion MNIST
train_set = FashionMNIST('./data', train=True, download=True) #lets get a different training set and test set
test_set = FashionMNIST('./data', train=False, download=True)

X = train_set.data.numpy() #we'll change them to numpy arrays so we can do our torch functions on them
X_test = test_set.data.numpy()
Y = train_set.targets.numpy()
Y_test = test_set.targets.numpy()
X = X[:,None,:,:]/255
X_test = X_test[:,None,:,:]/255
X = (X - 0.5)/0.5
X_test = (X_test - 0.5)/0.5

n = 7

index = np.where(Y == n)
X = X[index]
index = np.where(Y_test == n)
X_test = X_test[index]

X.shape,Y.shape,X_test.shape,Y_test.shape

###################################################

X = GPU_data(X)
X_test = GPU_data(X_test)
Y = GPU_data(Y)
Y_test = GPU_data(Y_test)

x,y = get_batch('train')



x.shape

montage_plot(x[0:25,0,:,:].detach().cpu().numpy())

#D
w0 = GPU(randn_trunc((64,1,4,4)))
w1 = GPU(randn_trunc((128,64,4,4)))
w2 = GPU(randn_trunc((1,6272)))
#G
w3 = GPU(randn_trunc((6272,64)))
w4 = GPU(randn_trunc((128,64,4,4)))
w5 = GPU(randn_trunc((64,1,4,4)))

w = [w0,w1,w2,w3,w4,w5]

def D(x,w):
    x = relu(conv2d(x,w[0], stride=(2, 2), padding=(1, 1)))
    x = relu(conv2d(x,w[1], stride=(2, 2), padding=(1, 1)))
    x = x.view(x.size(0), 6272)
    x = linear(x,w[2])
    x = torch.sigmoid(x)
    return x

def G(x,w):
    x = linear(x,w[3])
    x = x.view(x.size(0), 128, 7, 7)
    x = relu(conv_transpose2d(x,w[4], stride=(2, 2), padding=(1, 1)))
    x = torch.tanh(conv_transpose2d(x,w[5], stride=(2, 2), padding=(1, 1)))
    return x

b = 1024

batch_size = b

batch_size

d_optimizer = torch.optim.Adam(w[0:3], lr=0.0002)
g_optimizer = torch.optim.Adam(w[3:], lr=0.0002)

real_labels = (torch.ones(batch_size, 1).cuda())
fake_labels = (torch.zeros(batch_size, 1).cuda())

num_epochs = 500
batches = X.shape[0]//batch_size
steps = num_epochs*batches

z1 = (torch.randn(steps,batch_size,latent_size).cuda())
z2 = (torch.randn(steps,batch_size,latent_size).cuda())

for i in range(steps):

    images,y = get_batch('train')

    d_loss = binary_cross_entropy(D(images,w), real_labels) + binary_cross_entropy(D(G(z1[i],w),w), fake_labels)
    d_optimizer.zero_grad()
    d_loss.backward()
    d_optimizer.step()


    g_loss = binary_cross_entropy(D(G(z2[i],w),w), real_labels)
    g_optimizer.zero_grad()
    g_loss.backward()
    g_optimizer.step()


    if i % 200 == 0:
        out = G(z1[np.random.randint(steps)],w)
        montage_plot(out.view(batch_size,1,28,28).detach().cpu().numpy()[0:25,0,:,:])





z1[np.random.randint(steps)].shape

noise = GPU_data(torch.randn(1,64))

output = G(noise,w)

output.shape

plot(output[0,0]) #see how much our first index improved over time



















